# FS Airflow Documentation

Welcome to the FS Airflow Documentation. This project serves as a concise example of foundational infrastructure for standard data engineering projects, specifically designed for batch processing. In the `./dags` folder, you will find an illustrative example of data extraction from a Pok√©mon API, with the resulting data being stored in an Amazon S3 bucket in the form of a .csv file.

## Prerequisites
Before you can successfully utilize this project, please ensure you have the following prerequisites in place:

- Docker
- Terraform
- Python 3.10.8
- An active AWS account with administrative access
- Access to the main application infrastructure repository, which can be found [here](https://github.com/NelsonECandia/fs_infrastructure).

With these prerequisites met, you'll be well-prepared to make the most of FS Airflow's capabilities.
